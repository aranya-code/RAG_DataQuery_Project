{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d39256",
   "metadata": {},
   "source": [
    "### Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7e2a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d9711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: New CSV for Morning Call.xlsx\n",
      "Processing: New Updated CSV3.xlsx\n",
      "Successfully loaded 92157 dynamic chunks from Excel files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Order Creation Date': Timestamp('2024-12-31 00:00:00'), 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 180.0, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 180.0 | IsBillComplete: 0'),\n",
       " Document(metadata={'Order Creation Date': Timestamp('2024-12-31 00:00:00'), 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 0.0, 'IsBillComplete': 1, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 0.0 | IsBillComplete: 1'),\n",
       " Document(metadata={'Order Creation Date': Timestamp('2024-12-31 00:00:00'), 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 111.15, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 111.15 | IsBillComplete: 0'),\n",
       " Document(metadata={'Order Creation Date': Timestamp('2024-12-31 00:00:00'), 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 111.15, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 111.15 | IsBillComplete: 0'),\n",
       " Document(metadata={'Order Creation Date': Timestamp('2024-12-31 00:00:00'), 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 111.15, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 111.15 | IsBillComplete: 0')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_excel(excel_directory, target_column=None):\n",
    "    all_documents = []\n",
    "    excel_dir = Path(excel_directory)\n",
    "    excel_files = list(excel_dir.glob('**/*.xlsx'))\n",
    "\n",
    "    if not excel_files:\n",
    "        print(f\"No Excel files found in {excel_directory}\")\n",
    "        return []\n",
    "\n",
    "    for excel_file in excel_files:\n",
    "        print(f\"Processing: {excel_file.name}\")\n",
    "        try:\n",
    "            df = pd.read_excel(excel_file)\n",
    "            \n",
    "            # Logic 1: If user provided a specific column AND it exists in this file\n",
    "            if target_column and target_column in df.columns:\n",
    "                loader_column = target_column\n",
    "            \n",
    "            # Logic 2: If no column provided (or it's missing), create a smart combined row\n",
    "            else:\n",
    "                loader_column = 'combined_text'\n",
    "                # This attaches the header name to the value so the AI has perfect context\n",
    "                df[loader_column] = df.apply(\n",
    "                    lambda row: ' | '.join(f\"{col}: {val}\" for col, val in row.items() if pd.notnull(val)), \n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "            # Pass the dynamically selected column to the loader\n",
    "            loader = DataFrameLoader(df, page_content_column=loader_column)\n",
    "            documents = loader.load()\n",
    "\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = excel_file.name\n",
    "                doc.metadata['file_type'] = \"xlsx\"\n",
    "                \n",
    "            all_documents.extend(documents)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {excel_file.name}: {e}\")\n",
    "\n",
    "    print(f\"Successfully loaded {len(all_documents)} dynamic chunks from Excel files.\")\n",
    "    return all_documents\n",
    "\n",
    "# Example usage:\n",
    "excel_docs = process_excel('../data/excel_files', target_column='YourColumn')\n",
    "excel_docs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df783ed",
   "metadata": {},
   "source": [
    "### Embedding and VectorStore DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dca97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd740618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 109.94it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding Manager successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name = 'all-MiniLM-L6-v2'):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model(model_name)\n",
    "\n",
    "    def _load_model(self, model_name):\n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model '{model_name}': {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]):\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        try:\n",
    "            embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating embeddings: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_embedding_dimensions(self):\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "# Initialize the manager (Notice we removed the trailing variable!)\n",
    "embedding_manager = EmbeddingManager()\n",
    "print(\"âœ… Embedding Manager successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa29fbb",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3668ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized with collection: all_excel_documents\n",
      "âœ… Vector Store ready!\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, collection_name='all_excel_documents', persist_directory='../data/vector_store/excel/'):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_chromadb()\n",
    "\n",
    "    def _initialize_chromadb(self):\n",
    "        try:\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "        \n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                # Updated this description to reflect your Excel data!\n",
    "                metadata={\"description\": \"Excel document chunks with embeddings\"} \n",
    "            )\n",
    "\n",
    "            print(f'Vector store initialized with collection: {self.collection_name}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents and embeddings must match.\")\n",
    "        \n",
    "        # Prepare the chromadb entries\n",
    "        ids = []\n",
    "        metadata_list = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate a unique ID for each document\n",
    "            doc_id = f'doc_{uuid.uuid4().hex[:8]}_{i}'\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadata_list.append(metadata)\n",
    "              \n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Pro-tip: Ensure the math vector is a standard Python list for ChromaDB\n",
    "            if isinstance(embedding, np.ndarray):\n",
    "                embeddings_list.append(embedding.tolist())\n",
    "            else:\n",
    "                embeddings_list.append(embedding)\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadata_list\n",
    "            )\n",
    "\n",
    "            print(f'Successfully added {len(documents)} documents to the vector store.')\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to ChromaDB: {e}\")\n",
    "            raise\n",
    "\n",
    "# Initialize the connection (Trailing variable removed!)\n",
    "vector_store = VectorStore()\n",
    "print(\"âœ… Vector Store ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a86ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning 92,157 metadata dictionaries...\n",
      "âœ… Metadata cleaned and ready for ChromaDB!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Order Creation Date': '2024-12-31 00:00:00', 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 180.0, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 180.0 | IsBillComplete: 0'),\n",
       " Document(metadata={'Order Creation Date': '2024-12-31 00:00:00', 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 0.0, 'IsBillComplete': 1, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 0.0 | IsBillComplete: 1'),\n",
       " Document(metadata={'Order Creation Date': '2024-12-31 00:00:00', 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 111.15, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 111.15 | IsBillComplete: 0'),\n",
       " Document(metadata={'Order Creation Date': '2024-12-31 00:00:00', 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 111.15, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 111.15 | IsBillComplete: 0'),\n",
       " Document(metadata={'Order Creation Date': '2024-12-31 00:00:00', 'OrderBusinessUnitName': 'The Morning Call', 'TotalPrice': 111.15, 'IsBillComplete': 0, 'source_file': 'New CSV for Morning Call.xlsx', 'file_type': 'xlsx'}, page_content='Order Creation Date: 2024-12-31 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 111.15 | IsBillComplete: 0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cleaning 92,157 metadata dictionaries...\")\n",
    "\n",
    "# Connect our loaded Pandas documents\n",
    "chunks = excel_docs\n",
    "\n",
    "for chunk in chunks:\n",
    "    # We iterate through the keys as a list so we can modify the dictionary safely\n",
    "    for key in list(chunk.metadata.keys()):\n",
    "        value = chunk.metadata[key]\n",
    "        # If ChromaDB won't accept the type, we cast it to a standard string\n",
    "        if not isinstance(value, (str, int, float, bool)):\n",
    "            chunk.metadata[key] = str(value)\n",
    "            \n",
    "print(\"âœ… Metadata cleaned and ready for ChromaDB!\")\n",
    "\n",
    "chunks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8224f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to safely embed 92157 rows into ChromaDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Progress:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:02<00:00,  1.29it/s]\n",
      "Embedding Progress:   5%|â–Œ         | 1/19 [02:13<39:59, 133.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:04<00:00,  1.26it/s]\n",
      "Embedding Progress:  11%|â–ˆ         | 2/19 [04:26<37:44, 133.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:53<00:00,  1.38it/s]\n",
      "Embedding Progress:  16%|â–ˆâ–Œ        | 3/19 [06:30<34:25, 129.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:54<00:00,  1.37it/s]\n",
      "Embedding Progress:  21%|â–ˆâ–ˆ        | 4/19 [08:34<31:43, 126.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:54<00:00,  1.37it/s]\n",
      "Embedding Progress:  26%|â–ˆâ–ˆâ–‹       | 5/19 [10:37<29:20, 125.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:18<00:00,  1.13it/s]\n",
      "Embedding Progress:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [13:10<29:14, 134.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:16<00:00,  1.15it/s]\n",
      "Embedding Progress:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [15:36<27:43, 138.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:55<00:00,  1.36it/s]\n",
      "Embedding Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [17:41<24:36, 134.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:49<00:00,  1.43it/s]\n",
      "Embedding Progress:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [19:40<21:33, 129.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:51<00:00,  1.41it/s]\n",
      "Embedding Progress:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [21:42<19:04, 127.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:50<00:00,  1.42it/s]\n",
      "Embedding Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [23:43<16:41, 125.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:49<00:00,  1.43it/s]\n",
      "Embedding Progress:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [25:42<14:23, 123.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:47<00:00,  1.46it/s]\n",
      "Embedding Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [27:41<12:11, 121.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:50<00:00,  1.43it/s]\n",
      "Embedding Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [29:41<10:07, 121.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:55<00:00,  1.36it/s]\n",
      "Embedding Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [31:46<08:10, 122.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:00<00:00,  1.31it/s]\n",
      "Embedding Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [33:58<06:16, 125.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:58<00:00,  1.32it/s]\n",
      "Embedding Progress:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [36:07<04:12, 126.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 5000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:01<00:00,  1.30it/s]\n",
      "Embedding Progress:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [38:20<02:08, 128.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 5000 documents to the vector store.\n",
      "Generating embeddings for 2157 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:54<00:00,  1.25it/s]\n",
      "Embedding Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [39:19<00:00, 124.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 2157 documents to the vector store.\n",
      "\n",
      "âœ… Success! All 92,157 rows of Morning Call data are completely ingested!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"Preparing to safely embed {len(chunks)} rows into ChromaDB...\")\n",
    "\n",
    "# Processing 100 rows at a time\n",
    "batch_size = 5000\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Embedding Progress\"):\n",
    "        # Grab the current slice\n",
    "        batch_chunks = chunks[i : i + batch_size]\n",
    "        \n",
    "        # Extract the text string\n",
    "        texts_to_embed = [chunk.page_content for chunk in batch_chunks]\n",
    "        \n",
    "        # Generate the math vectors\n",
    "        new_embeddings = embedding_manager.generate_embeddings(texts_to_embed)\n",
    "        \n",
    "        # Add them directly to your existing ChromaDB collection\n",
    "        vector_store.add_documents(batch_chunks, new_embeddings)\n",
    "        \n",
    "    print(\"\\nâœ… Success! All 92,157 rows of Morning Call data are completely ingested!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error adding to database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10defea8",
   "metadata": {},
   "source": [
    "### Retriever pipeline from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98f2091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized with collection: all_excel_documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 112.92it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles the retrieval of relevant document chunks based on a query.\"\"\"\n",
    "\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 50, score_threshold: float = 0.5):\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        try:\n",
    "            # Perform the query to get relevant documents\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k,\n",
    "                include=['documents', 'metadatas', 'embeddings', 'distances']\n",
    "            )\n",
    "\n",
    "            retrieved_docs = []\n",
    "            documents = results.get('documents', [])[0]\n",
    "            metadatas = results.get('metadatas', [])[0]\n",
    "            distances = results.get('distances', [])[0]\n",
    "            ids = results.get('ids', [])[0]\n",
    "\n",
    "            # Check if the query returned any results\n",
    "            if not documents:\n",
    "                print(\"No documents found\")\n",
    "                return []\n",
    "\n",
    "            # Process the results and filter based on similarity score\n",
    "            for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                similarity_score = 1.0 - (distance / 2.0) # Higher similarity means a smaller distance\n",
    "                \n",
    "                if similarity_score >= score_threshold:\n",
    "                    retrieved_docs.append({\n",
    "                        'id': doc_id,\n",
    "                        'content': document,\n",
    "                        'metadata': metadata,\n",
    "                        'similarity_score': similarity_score,\n",
    "                        'distance': distance,\n",
    "                        'rank': i + 1\n",
    "                    })\n",
    "\n",
    "            if not retrieved_docs:\n",
    "                print(f\"No documents meet the score threshold of {score_threshold}\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Make sure vector_store and embedding_manager are instantiated before passing them to the RAGRetriever\n",
    "vector_store = VectorStore()  # Assuming you have this class set up\n",
    "embedding_manager = EmbeddingManager()  # Assuming you have this class set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "068e66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 92,000+ rows for: 'What is the TotalPrice for The Morning Call?'\n",
      "\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 10 matching rows!\n",
      "\n",
      "--- TOP 3 MATCHES ---\n",
      "Match 1 (Score: 0.55):\n",
      "Order Creation Date: 2022-10-10 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 86.4025 | IsBillComplete: 1\n",
      "----------------------------------------\n",
      "Match 2 (Score: 0.54):\n",
      "Order Creation Date: 2024-10-10 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 88.275 | IsBillComplete: 1\n",
      "----------------------------------------\n",
      "Match 3 (Score: 0.54):\n",
      "Order Creation Date: 2024-10-10 00:00:00 | OrderBusinessUnitName: The Morning Call | TotalPrice: 88.275 | IsBillComplete: 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the retriever (using your existing connections)\n",
    "rag_retriever = RAGRetriever(vector_store, embedding_manager)\n",
    "\n",
    "# 2. Write a test query that matches your Excel data\n",
    "query = \"What is the TotalPrice for The Morning Call?\"\n",
    "\n",
    "# 3. Run the search! (Notice we increased top_k and lowered the threshold)\n",
    "print(f\"Searching 92,000+ rows for: '{query}'\\n\")\n",
    "retrieved_docs = rag_retriever.retrieve(query, top_k=10, score_threshold=0.2)\n",
    "\n",
    "# 4. Print out the results so we can see what the AI will read\n",
    "if retrieved_docs:\n",
    "    print(f\"âœ… Found {len(retrieved_docs)} matching rows!\\n\")\n",
    "    print(\"--- TOP 3 MATCHES ---\")\n",
    "    for i in range(min(3, len(retrieved_docs))):\n",
    "        doc = retrieved_docs[i]\n",
    "        print(f\"Match {i+1} (Score: {doc['similarity_score']:.2f}):\")\n",
    "        print(doc['content'])\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"âŒ No matching rows found. Try lowering the threshold further.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "860b8a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Searching the database...\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Gemini is reading the rows and generating an answer...\n",
      "Error generating response: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 45.363378829s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 45.363378829s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 4. Generate the final answer\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ§  Gemini is reading the rows and generating an answer...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m final_answer = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieved_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m25\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== FINAL RAG ANSWER ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36msimple_rag_retriever.generate_response\u001b[39m\u001b[34m(self, query, retrieved_docs)\u001b[39m\n\u001b[32m     23\u001b[39m         prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a helpful assistant answering questions based on the provided documents.\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33mUsing only the text below, answer the question. If the answer is not contained in the context, say \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mI do not have enough information to answer that.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33mAnswer:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m             \u001b[38;5;66;03m# THE FIX: Explicitly stating model= and contents=\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m             response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m response.text.strip()\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\models.py:5644\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5642\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5643\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5644\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5645\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5646\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5648\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5649\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\models.py:4306\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4303\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   4304\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4306\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4307\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4308\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4311\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4312\u001b[39m ):\n\u001b[32m   4313\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\_api_client.py:1401\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1392\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1393\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1396\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1397\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1398\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1399\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1400\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1402\u001b[39m   response_body = (\n\u001b[32m   1403\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1404\u001b[39m   )\n\u001b[32m   1405\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\_api_client.py:1237\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1234\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    369\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:413\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    411\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:184\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    475\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\_api_client.py:1214\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1207\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1208\u001b[39m       method=http_request.method,\n\u001b[32m   1209\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1212\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1213\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1214\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1215\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1216\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1217\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    161\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 45.363378829s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "class simple_rag_retriever:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.model_name = \"gemini-2.5-flash-lite\" \n",
    "        \n",
    "    def generate_response(self, query, retrieved_docs):\n",
    "        if not retrieved_docs:\n",
    "            return \"Error: The retriever returned 0 chunks. The context is empty!\"\n",
    "\n",
    "        # Context Injection\n",
    "        context_chunks = [doc['content'] for doc in retrieved_docs]\n",
    "        context_string = \"\\n\\n---\\n\\n\".join(context_chunks)\n",
    "\n",
    "        # Constructing the prompt\n",
    "        prompt = f\"\"\"You are a helpful assistant answering questions based on the provided documents.\n",
    "Using only the text below, answer the question. If the answer is not contained in the context, say \"I do not have enough information to answer that.\"\n",
    "        \n",
    "Context:\n",
    "{context_string}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # THE FIX: Explicitly stating model= and contents=\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model_name,\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            raise\n",
    "\n",
    "# 1. Ask a specific question about your columns!\n",
    "query = \"get me OrderBusinessUnitName names\"\n",
    "\n",
    "# 2. Retrieve the documents (Bumping up top_k so Gemini gets more context!)\n",
    "print(\"ðŸ” Searching the database...\")\n",
    "retrieved_docs = rag_retriever.retrieve(query, top_k=50, score_threshold=0.0)\n",
    "\n",
    "# 3. Initialize generator\n",
    "generator = simple_rag_retriever(api_key)\n",
    "\n",
    "# 4. Generate the final answer\n",
    "print(\"ðŸ§  Gemini is reading the rows and generating an answer...\")\n",
    "final_answer = generator.generate_response(query, retrieved_docs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*25)\n",
    "print(\"=== FINAL RAG ANSWER ===\")\n",
    "print(\"=\"*25)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673764a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Ensure your data is loaded into a single DataFrame (You likely already have this!)\n",
    "excel_files = list(Path('../data/excel_files').glob('**/*.xlsx'))\n",
    "all_data = pd.concat([pd.read_excel(f) for f in excel_files])\n",
    "\n",
    "# 2. Connect to Gemini (Using the LangChain integration)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    google_api_key=api_key,\n",
    "    temperature=0 # Keep it at 0 so it writes strict, accurate Pandas code\n",
    ")\n",
    "\n",
    "# 3. Create the Agent\n",
    "pandas_agent = create_pandas_dataframe_agent(\n",
    "    llm,\n",
    "    all_data, \n",
    "    verbose=True, # Set to True so you can watch the AI write the Python code!\n",
    "    allow_dangerous_code=True # Required to allow the AI to run Pandas functions locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa7de50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST 1: A qualitative question ---\n",
      "ðŸ” STEP 1: Asking the Vector Database...\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating response: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 7.007285062s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 7.007285062s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# --- Test it out! ---\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- TEST 1: A qualitative question ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43msmart_ask\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the TotalPrice for the orders from The Morning Call? Tell me if the bills are complete.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m time.sleep(\u001b[32m25\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- TEST 2: A global aggregation question ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36msmart_ask\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Try the Vector RAG first\u001b[39;00m\n\u001b[32m      7\u001b[39m retrieved_docs = rag_retriever.retrieve(query, top_k=\u001b[32m20\u001b[39m, score_threshold=\u001b[32m0.2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m rag_answer = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieved_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Check if the Vector Database failed!\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mI do not have enough information\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m rag_answer:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36msimple_rag_retriever.generate_response\u001b[39m\u001b[34m(self, query, retrieved_docs)\u001b[39m\n\u001b[32m     23\u001b[39m         prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a helpful assistant answering questions based on the provided documents.\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33mUsing only the text below, answer the question. If the answer is not contained in the context, say \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mI do not have enough information to answer that.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33mAnswer:\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m             \u001b[38;5;66;03m# THE FIX: Explicitly stating model= and contents=\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m             response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m response.text.strip()\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\models.py:5644\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5642\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5643\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5644\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5645\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5646\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5648\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5649\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\models.py:4306\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4303\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   4304\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4306\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4307\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4308\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4311\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4312\u001b[39m ):\n\u001b[32m   4313\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\_api_client.py:1401\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1392\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1393\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1396\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1397\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1398\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1399\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1400\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1402\u001b[39m   response_body = (\n\u001b[32m   1403\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1404\u001b[39m   )\n\u001b[32m   1405\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\_api_client.py:1237\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1234\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    369\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:413\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    411\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:184\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tenacity\\__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    475\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\_api_client.py:1214\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1207\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1208\u001b[39m       method=http_request.method,\n\u001b[32m   1209\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1212\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1213\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1214\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1215\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1216\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1217\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arany\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\genai\\errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    161\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 7.007285062s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def smart_ask(query):\n",
    "    print(\"ðŸ” STEP 1: Asking the Vector Database...\")\n",
    "    \n",
    "    # 1. Try the Vector RAG first\n",
    "    retrieved_docs = rag_retriever.retrieve(query, top_k=20, score_threshold=0.2)\n",
    "    rag_answer = generator.generate_response(query, retrieved_docs)\n",
    "    \n",
    "    # 2. Check if the Vector Database failed!\n",
    "    if \"I do not have enough information\" in rag_answer:\n",
    "        print(\"âš ï¸ Vector DB doesn't have the global view. Switching to Pandas Agent...\")\n",
    "        print(\"ðŸ¤– STEP 2: Agent is analyzing the entire DataFrame...\")\n",
    "        \n",
    "        # 3. Trigger the Pandas Agent as a fallback\n",
    "        try:\n",
    "            pandas_response = pandas_agent.invoke(query)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*30)\n",
    "            print(\"=== FINAL ANSWER (From Pandas) ===\")\n",
    "            print(\"=\"*30)\n",
    "            print(pandas_response['output'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Both methods failed. Agent Error: {e}\")\n",
    "            \n",
    "    else:\n",
    "        # If it didn't say the failure phrase, the RAG succeeded!\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(\"=== FINAL ANSWER (From Vector DB) ===\")\n",
    "        print(\"=\"*30)\n",
    "        print(rag_answer)\n",
    "\n",
    "# --- Test it out! ---\n",
    "print(\"--- TEST 1: A qualitative question ---\")\n",
    "smart_ask(\"What is the TotalPrice for the orders from The Morning Call? Tell me if the bills are complete.\")\n",
    "\n",
    "time.sleep(25)\n",
    "\n",
    "print(\"\\n\\n--- TEST 2: A global aggregation question ---\")\n",
    "smart_ask(\"What are all the unique OrderBusinessUnitName values in the dataset?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
